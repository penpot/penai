from abc import abstractmethod
import abc
from collections.abc import Iterable
from dataclasses import dataclass, field
from functools import cached_property
import json
from typing import Generic, Self, TypeVar

from langchain_core.output_parsers import BaseOutputParser, JsonOutputParser
from langchain_core.prompts import PromptTemplate
from langchain_core.pydantic_v1 import BaseModel
from tqdm import tqdm

from penai.llm.conversation import Conversation, MessageBuilder, Response
from penai.llm.llm_model import RegisteredLLM, RegisteredLLMParams
from penai.svg import BoundingBox, PenpotShapeElement
from penai.utils.vis import ShapeVisualization, ShapeVisualizer


class InferencedHierarchySchema(BaseModel):
    """The data schema for the inferred shape hierarchy as expected to be generated by an LLM."""

    id: str
    description: str
    children: list["InferencedHierarchySchema"] | None = None

    def flatten(self) -> Iterable["InferencedHierarchySchema"]:
        yield self

        if self.children:
            for child in self.children:
                yield from child.flatten()


@dataclass
class HierarchyElement:
    """An element within the inferred hierarchy of shapes.

    In opposition to the `InferencedHierarchySchema`, this class assumes that the hierarchy
    has already been validated and offers a more convenient interface.
    """

    shape: PenpotShapeElement
    description: str
    parent: Self | None = None
    children: list[Self] = field(default_factory=list)

    @classmethod
    def from_hierarchy_schema(
        cls,
        label_shape_mapping: dict[str, PenpotShapeElement],
        source_element: InferencedHierarchySchema,
        parent: Self | None = None,
    ) -> Self:
        element = cls(
            shape=label_shape_mapping[source_element.id],
            description=source_element.description,
            parent=parent,
        )

        for child in source_element.children or []:
            element.children.append(
                cls.from_hierarchy_schema(label_shape_mapping, child, element)
            )

        return element

    def flatten(self) -> Iterable[Self]:
        yield self

        for child in self.children:
            yield from child.flatten()

    @cached_property
    def bbox(self) -> BoundingBox:
        return BoundingBox.from_view_box_string(
            self.shape._lxml_element.attrib["viewBox"]
        )


SchemaType = TypeVar("SchemaType", bound=BaseModel)


class SchemaResponse(Response, Generic[SchemaType]):
    def __init__(self, response_text: str, parser: BaseOutputParser) -> None:
        super().__init__(response_text)
        self.parser = parser

    def parse_response(self) -> SchemaType:
        return self.parser.invoke(self.text)


# class BaseDesignDocumentInferencer(abc.ABC):
#     def __init__(
#         self,
#         shape_visualizer: ShapeVisualizer,
#         model: RegisteredLLM = RegisteredLLM.GPT4O,
#         system_message: SystemMessage | None = None,
#         **model_options: RegisteredLLMParams,
#     ) -> None:
#         self.shape_visualizer = shape_visualizer
#         self.model = model
#         self.model_options = model_options
#         self.system_message = system_message

#     @abc.abstractmethod
#     def build_user_message(
#         self, root_shape: PenpotShapeElement, visualizations: list[ShapeVisualization]
#     ) -> HumanMessage:
#         pass

#     def query(
#         self,
#         shape: PenpotShapeElement,
#         schema: type[SchemaType],
#         return_artifacts: bool = False,
#     ) -> SchemaType | tuple[SchemaType, list[ShapeVisualization]]:
#         num_shapes = len(list(shape.get_all_children_shapes())) + 1

#         if num_shapes > self.max_shapes:
#             raise ValueError(
#                 f"Too many shapes to infer hierarchy: {num_shapes} > {self.max_shapes}"
#             )

#         visualizations = list(
#             tqdm(self.shape_visualizer.visualize_bboxes_in_shape(shape))
#         )

#         messages = [
#             self.system_message,
#             self.build_user_message(shape, visualizations),
#         ]

#         model = self.model.create_model(**self.model_options)

#         model.invoke()
#         parser = JsonOutputParser(pydantic_object=schema)

#         conversation = Conversation(
#             model=self.model,
#             response_factory=lambda text: SchemaResponse(text, parser),
#             **self.model_options,
#         )
#         response = conversation.query(prompt)
#         result = response.parse_response()

#         if return_artifacts:
#             return result, visualizations

#         return result


# class BasicDesignDocumentInferencer(BaseDesignDocumentInferencer):
#     @abc.abs
#     def build_prompt_for_shape(self, shape_visualization: ShapeVisualization) -> str:
#         pass

#     def build_prompt(
#         self, root_shape: PenpotShapeElement, visualizations: list[ShapeVisualization]
#     ) -> str:
#         return super().build_prompt(root_shape, visualizations)


class HierarchyInferencer:
    parser = JsonOutputParser(pydantic_object=InferencedHierarchySchema)

    prompt_template = PromptTemplate(
        template="{query}\n{format_instructions}\n",
        input_variables=["query"],
        partial_variables={"format_instructions": parser.get_format_instructions()},
    )

    def __init__(
        self,
        shape_visualizer: ShapeVisualizer,
        model: RegisteredLLM = RegisteredLLM.GPT4O,
        validate_hierarchy: bool = True,
        max_shapes: int = 200,
        **model_options: RegisteredLLMParams,
    ) -> None:
        self.shape_visualizer = shape_visualizer
        self.model = model
        self.model_options = model_options
        self.validate_hierarchy = validate_hierarchy
        self.max_shapes = max_shapes

    def build_prompt(self, visualizations: list[ShapeVisualization]) -> str:
        query = (
            "Provided are screenshots from a design document. "
            f"Each of the {len(visualizations)} design elements is depicted with its bounding box and a tooltip above with the unique element id and the element type. "
            "Provide a logical hierarchy between those elements reflecting their semantics and spatial relationships. "
            "Additionally, provide a short and meaningful description for each element in natural language as it could appear in the layer hierarchy of a design software. "
            # "The hierarchy and description should be precise enough so that a blind person can figure out the design.\n"
        )

        message = MessageBuilder()
        message.with_text_message(self.prompt_template.format(query=query))

        for visualization in visualizations:
            # message.with_text_message("Element ID: " + visualization.label + "\n")
            message.with_image(visualization.image)
            # message.with_text_message("\n\n")

        return message.build()

    def infer_shape_hierarchy(
        self,
        shape: PenpotShapeElement,
        return_visualizations: bool = False,
    ) -> HierarchyElement | tuple[HierarchyElement, list[ShapeVisualization]]:
        num_shapes = len(list(shape.get_all_children_shapes())) + 1

        if num_shapes > self.max_shapes:
            raise ValueError(
                f"Too many shapes to infer hierarchy: {num_shapes} > {self.max_shapes}"
            )

        visualizations = list(
            tqdm(self.shape_visualizer.visualize_bboxes_in_shape(shape))
        )

        prompt = self.build_prompt(visualizations)

        conversation = Conversation(
            model=self.model,
            response_factory=lambda text: SchemaResponse(text, self.parser),
            **self.model_options,
        )
        response = conversation.query(prompt)
        queried_hierarchy = response.parse_response()

        label_shape_mapping = {
            vis.label.replace("#", ""): vis.shape for vis in visualizations
        }

        hierarchy = HierarchyElement.from_hierarchy_schema(
            label_shape_mapping, queried_hierarchy
        )

        if return_visualizations:
            return hierarchy, visualizations

        return hierarchy


class DescriptionGenerator:
    def __init__(
        self,
        shape_visualizer: ShapeVisualizer,
        model: RegisteredLLM = RegisteredLLM.GPT4O,
        validate_result: bool = True,
        **model_options: RegisteredLLMParams,
    ) -> None:
        self.shape_visualizer = shape_visualizer
        self.model = model
        self.model_options = model_options
        self.validate_result = validate_result

    def add_shape_to_message(
        self, message_builder: MessageBuilder, shape_vis: ShapeVisualization
    ) -> None:
        message_builder.with_text_message(
            f"Element ID: {shape_vis.label} (type: {shape_vis.shape.type.value})"
        )
        message_builder.with_image(shape_vis.image)
        message_builder.with_text_message("\n\n")

    def generate_descriptions(self, shape: PenpotShapeElement) -> dict[str, str]:
        system_message = (
            MessageBuilder()
            .with_text_message(
                "The users of our design software need help naming the design elements in their design document. You will be provided with an image for each design element in the document that depicts its bounding box and ID. Provide a short description for each design element in JSON format wrapped in Markdown with the following schema per element: {\"<ID>\": \"<Description>\"}. This description will appear in the document hierarchy and should help in understanding and editing the document. Take the spatial and semantic relationships between the elements into account when providing the descriptions. Use nominalizations and avoid verb forms, i.e. \"Car button icon\" instead of \"Button icon displaying a car\". Do not include the element type or category in the description."
            )
            .build_system_message()
        )

        human_message_builder = MessageBuilder()

        visualizations = self.shape_visualizer.visualize_bboxes_in_shape(shape)

        for shape_vis in visualizations:
            self.add_shape_to_message(human_message_builder, shape_vis)

        human_message = human_message_builder.build_human_message()

        model = self.model.create_model(**self.model_options)

        response = Response(model.invoke([system_message, human_message]).content)

        code_snippets = response.get_code_snippets()

        assert (
            len(code_snippets) == 1
        ), f"Expected exactly one code snippet in the response but got {len(code_snippets)}."

        result = json.loads(code_snippets[0].code)

        label_shape_mapping = {vis.label: vis.shape.shape_id for vis in visualizations}

        mapped_result = {}

        for label, description in result.items():
            if label not in label_shape_mapping:
                raise KeyError(
                    f'Model generated response which includes label "{label}". '
                    "However this label does not correspond to any known shape. "
                    "The model likely hallucinated a label which may indicate a bad prompt or inproper inputs."
                )

            mapped_result[label_shape_mapping[label]] = description

        if self.validate_result:
            diff = set(mapped_result.keys()) - set(label_shape_mapping.values())
            assert (
                not diff
            ), f"The following shape ids are missing from the generated output: {diff}"

        return mapped_result
